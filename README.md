# Autism_screening_in_children_using_XAI
 Memory updated Here’s a concise version:  ASD Screening AI: Developed an AI system to screen autism in children using machine learning. Employed SHAP and LIME for explainable AI, ensuring model transparency and trust in predictions.

*Autism spectrum disorder (ASD) is a developmental disability caused by differences in the brain. People
with ASD often have problems with social communication and interaction, and restricted or repetitive
behaviors or interests. People with ASD may also have different ways of learning, moving, or paying
attention.
Our project is to develop an expandable AI to screen autism in children

*Explainable artificial intelligence (XAI) is a set of processes and methods that allows human users to
comprehend and trust the results and output created by machine learning algorithms. Explainable AI is
used to describe an AI model, its expected impact and potential biases. It helps characterize model
accuracy, fairness, transparency and outcomes in AI-powered decision making. Explainable AI is crucial
for an organization in building trust and confidence when putting AI models into production.
There are 2 methods in XAI:
 ·Shap:
 It stands for Shapley Additive explanations. This method aims to
explain the prediction of an instance/observation by computing the contribution of each feature to the
prediction.
 ·Lime:
 It stands for Local Interpretable Model Agnostic Explanation. The local
aspect means that it is used to explain individual predictions of a machine learning model. It is used to
explain single instanc
